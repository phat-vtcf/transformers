{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "637c46f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import librosa\n",
    "\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a6e78dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# load pretrained model\n",
    "processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-base-960h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "478b566c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wav2vec_inference(wav_file):\n",
    "\n",
    "    # load audio\n",
    "    audio_input, sample_rate = librosa.load(wav_file, sr=16000)\n",
    "\n",
    "    # pad input values and return pt tensor\n",
    "    input_values = processor(audio_input, sampling_rate=sample_rate, return_tensors=\"pt\").input_values\n",
    "\n",
    "    #INFERENCE\n",
    "\n",
    "    # retrieve logits & take argmax\n",
    "    logits = model(input_values).logits\n",
    "    predicted_ids = torch.argmax(logits, dim=-1)\n",
    "\n",
    "    #transcribe\n",
    "    transcription = processor.decode(predicted_ids[0])\n",
    "\n",
    "    return transcription\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "120fda1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_45425/960127038.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mleminh_prediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwav2vec_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleminh_recording\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Prediction of {os.path.basename(leminh_recording)}: {leminh_prediction}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mtatsu_prediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwav2vec_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtatsu_recording\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "leminh_recording = 'audio_samples/leminh-wind-09092021.wav'\n",
    "tatsu_recording = 'audio_samples/tatsu-wind-09092021.wav'\n",
    "\n",
    "print()\n",
    "leminh_prediction = wav2vec_inference(leminh_recording)\n",
    "print(f'Prediction of {os.path.basename(leminh_recording)}: {leminh_prediction}')\n",
    "print()\n",
    "tatsu_prediction = wav2vec_inference(tatsu_recording)\n",
    "print(f'Prediction of {os.path.basename(tatsu_recording)}: {tatsu_prediction}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f69013e",
   "metadata": {},
   "source": [
    "## The code snippet below is for WER calcutation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289dae0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jiwer import wer\n",
    "\n",
    "# the script for the dictation\n",
    "original_text = \"THE NORTH WIND AND THE SUN WERE DISPUTING WHICH WAS THE STRONGER WHEN HE TRAVELLER CAME ALONG WRAPPED IN A WARM CLOAK DAY AGREED THAT THE ONE WHO FIRST SUCCEEDED IN MAKING THE TRAVELR TAKE HIS CLOAK OFF SHOULD BE CONSIDERED STRONGER THAN THE OTHER THEN THE NORTH WIND BLEW AS HARD AS HE COULD BUT THE MORE HE BLEW THE MORE CLOSELY TID THE TRAVELLER FOGT HIS CLOAK AROUND HIM AND AT LAST THE NORTH WIND GAVE UP THE ATTEMPT THEN THE SUN SHUNED OUT WARMLY AND IMMEDIDAELY THE TRAVELLER TOOK OFF HIS CLOAK AND SO THE NORTH WIND WAS OBLIGED TO CONFESS THAT THE SUN WAS THE STRONGER OFF THE TWIAK\"\n",
    "\n",
    "# WER is calculated in percentage.\n",
    "WER_leminh = wer(original_text, leminh_prediction)\n",
    "WER_tatsu = wer(original_text, tatsu_prediction)\n",
    "\n",
    "print(wer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
